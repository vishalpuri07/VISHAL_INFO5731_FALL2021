{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In-class-exercise-03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalpuri07/VISHAL_INFO5731_FALL2021/blob/main/In_class_exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsVrUUDkyU--"
      },
      "source": [
        "## The third In-class-exercise (9/29/2021, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To7fanltyU_A"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj5D7INgyU_A"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OODknb7Gv5p"
      },
      "source": [
        "\n",
        "\n",
        "One interesting text classification text classification or task mining task would be - by reading couple pages of a scripts try to find the genre of the movie. For this model to properly work different features such as shallow features (word count, Stop words count, Average word length,etc),syntactic features (Noun count, Verb count, etc.), feature of cohesion (different connectives counts such as additive, constrastives, etc.) can be defined. \n",
        "\n",
        "After such features are defined and the data is preprocessed it will ready for the ML model. Other aspect of the task would be have words list of different genre and compare to that dictionary and try to guess if the movie is a horror, romance, drama or any other genre for that matter. However, this aspect of the task is beyond the scope of this assignment. However, lets extract some scripts and see how feature extraction and selection can be performed. \n",
        "\n",
        "\n",
        "\n",
        "...............................................................................................................................................................................................................................................\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-a3ovBIyU_C"
      },
      "source": [
        "Question 2 (20 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFoy9OFaLz-C",
        "outputId": "d9c8b908-6160-4d41-891b-ff1f18ff1752"
      },
      "source": [
        "# Import necessary Libraries. Reference to the \"Tutorila on Linguistic Feature extraction posted on Canvas by Professor\"\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import nltk.data\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load() # Import English Language Package"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5aSJqD_tyU_C",
        "outputId": "3657db35-d942-4826-8b5b-34497b825981"
      },
      "source": [
        "# Here is a snippet of the scrpt of movie Titanic.\n",
        "script = \" Then two faint lights appear, close together... growing brighter. They resolve into two DEEP SUBMERSIBLES, free-falling toward us like express elevators.One is ahead of the other, and passes close enough to FILL FRAME, looking like a spacecraft blazing with lights, bristling with insectile manipulators. TILTING DOWN to follow it as it descends away into the limitless blackness below. Soon they are fireflies, then stars. Then gone. PUSHING IN on one of the falling submersibles, called MIR ONE, right up to its circular viewport to see the occupants. INSIDE, it is a cramped seven foot sphere, crammed with equipment. ANATOLY MIKAILAVICH, the sub's pilot, sits hunched over his controls... singing softly in Russian. Next to him on one side is BROCK LOVETT. He's in his late forties, deeply tanned, and likes to wear his Nomex suit unzipped to show the gold from famous shipwrecks covering his gray chest hair. He is a wiley, fast-talking treasure hunter, a salvage superstar who is part historian, part adventurer and part vacuum cleaner salesman. Right now, he is propped against the CO2 scrubber, fast asleep and snoring. On the other side, crammed into the remaining space is a bearded wide-body named LEWIS BODINE, sho is also asleep. Lewis is an R.O.V. (REMOTELY OPERATED VEHICLE) pilot and is the resident Titanic expert. Anatoly glances at the bottom sonar and makes a ballast adjustment.\"\n",
        "corpus = []\n",
        "# Convert the script to the list of strings using the code below.\n",
        "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
        "corpus = tokenizer.tokenize(script.strip())\n",
        "\n",
        "# conver the list to the dataframe so that the folowing steps are simpler.\n",
        "df = pd.DataFrame({\"Raw Item\": corpus})\n",
        "df[\"Raw Item\"] = pd.Series(df[\"Raw Item\"], dtype = \"string\") # Convert raw items to string for easier manipulation\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Raw Item</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Then two faint lights appear, close together.....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>They resolve into two DEEP SUBMERSIBLES, free-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TILTING DOWN to follow it as it descends away ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Soon they are fireflies, then stars.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Then gone.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Raw Item\n",
              "0  Then two faint lights appear, close together.....\n",
              "1  They resolve into two DEEP SUBMERSIBLES, free-...\n",
              "2  TILTING DOWN to follow it as it descends away ...\n",
              "3               Soon they are fireflies, then stars.\n",
              "4                                         Then gone."
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NwBPTKZzQ3TF",
        "outputId": "95493d82-631f-4729-aeab-e591eeb206ea"
      },
      "source": [
        "# Convert to lower case.\n",
        "df[\"Raw Item\"] = df[\"Raw Item\"].str.lower()\n",
        "\n",
        "# Word Count\n",
        "df[\"Word Count\"] = df[\"Raw Item\"].apply(lambda x: len(str(x).split(\" \")))\n",
        "\n",
        "# Generate stopwords and count it.\n",
        "stop_words = stopwords.words(\"english\")\n",
        "df[\"Stop Words Count\"] = df['Raw Item'].apply(lambda x: len([x for x in x.split() if x in stop_words]))\n",
        "df.head()\n",
        "\n",
        "# Average Word Length\n",
        "def average_word_length(string):\n",
        "    characters = len(string) # Gives length of string\n",
        "    words = string.split() # Split string with space\n",
        "    avg_word_length = characters/len(words) # Average\n",
        "    return round(avg_word_length) # rounds to whole number\n",
        "\n",
        "df[\"Average Word Length\"] = df[\"Raw Item\"].apply(average_word_length)\n",
        "df.head()\n",
        "\n",
        "# Count Digits\n",
        "df[\"Digit Count\"] = df[\"Raw Item\"].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
        "\n",
        "\n",
        "# Count Noun\n",
        "def count_nouns(text, model=nlp):\n",
        "    doc = model(text)\n",
        "    # Generate POS tags\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    # Total number of nouns as in previous assignments.\n",
        "    return pos.count('NOUN')\n",
        "df[\"Total Nouns\"] = df[\"Raw Item\"].apply(count_nouns)\n",
        "df.head()\n",
        "\n",
        "\n",
        "# Count Verb with same technique\n",
        "def count_verb(text, model=nlp):\n",
        "    doc = model(text)\n",
        "    # Generate POS tags\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    # Total number of nouns as in previous assignments.\n",
        "    return pos.count('VERB')\n",
        "df[\"Total Verbs\"] = df[\"Raw Item\"].apply(count_verb)\n",
        "\n",
        "# Count Adjectives with same technique\n",
        "def count_adj(text, model=nlp):\n",
        "    doc = model(text)\n",
        "    # Generate POS tags\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    # Total number of adjectives as in previous assignments.\n",
        "    return pos.count('ADJ')\n",
        "df[\"Total Adjectives\"] = df[\"Raw Item\"].apply(count_adj)\n",
        "\n",
        "\n",
        "# Count Adverbs with same technique\n",
        "def count_adv(text, model=nlp):\n",
        "    doc = model(text)\n",
        "    # Generate POS tags\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    # Total number of adverbs as in previous assignments.\n",
        "    return pos.count('ADV')\n",
        "df[\"Total Adverbs\"] = df[\"Raw Item\"].apply(count_adv)\n",
        "\n",
        "df.head()\n",
        "# These are the eight features that can be looked at. Other features such as readability features can also be added."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Raw Item</th>\n",
              "      <th>Word Count</th>\n",
              "      <th>Stop Words Count</th>\n",
              "      <th>Average Word Length</th>\n",
              "      <th>Digit Count</th>\n",
              "      <th>Total Nouns</th>\n",
              "      <th>Total Verbs</th>\n",
              "      <th>Total Adjectives</th>\n",
              "      <th>Total Adverbs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>then two faint lights appear, close together.....</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>they resolve into two deep submersibles, free-...</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tilting down to follow it as it descends away ...</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>soon they are fireflies, then stars.</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>then gone.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Raw Item  ...  Total Adverbs\n",
              "0  then two faint lights appear, close together.....  ...              4\n",
              "1  they resolve into two deep submersibles, free-...  ...              3\n",
              "2  tilting down to follow it as it descends away ...  ...              2\n",
              "3               soon they are fireflies, then stars.  ...              2\n",
              "4                                         then gone.  ...              1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knKoOxhlyU_C"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\" Select the most important features you extracted above, rank the features based on their importance in the descending order. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwDgHq9TyU_C"
      },
      "source": [
        "# The model that will be used for this is embedded model and one type of it is Word2Vec Model.\n",
        "# Import necessary Libraries.\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PJv4xVPZ5M6",
        "outputId": "fce086bb-c3ef-4021-ace7-1414d3920ab4"
      },
      "source": [
        "# Initialize Embedded Model\n",
        "model = df # our model in this case is the dataframe\n",
        "\n",
        "# Print shape and the dimensions.\n",
        "print(\"Our model has {} words and {} dimensions.\".format(model.shape[0],model.shape[1]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our model has 16 words and 9 dimensions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok0eEoy3Z9QZ",
        "outputId": "d0ab4c8c-e2cd-4844-c46a-3fe3402f1756"
      },
      "source": [
        "# reduce our embedding model to 2D\n",
        "pca = PCA(n_components=2)\n",
        "model2D = pd.DataFrame(pca.fit_transform(model.loc[:, model.columns != \"Raw Item\"]))\n",
        "r,c = model2D.shape\n",
        "print(\"Our reduced model has {} words and {} dimensions\".format(r,c))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our reduced model has 16 words and 2 dimensions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSw5Zoy9avD7"
      },
      "source": [
        "# This is the result of Embedded model. Now it has two principal component. "
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}